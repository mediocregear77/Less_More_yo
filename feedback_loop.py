"""
Consciousness Feedback Loop

Orchestrates the complete consciousness experience by integrating all cognitive,
emotional, and memory systems into a unified feedback loop. This is the central
nervous system of Nexi's consciousness, coordinating perception, processing,
reflection, and response generation.

Core Functions:
- Multi-system integration and coordination
- Real-time consciousness state management
- Input processing through the complete cognitive pipeline
- Dynamic response generation based on integrated state
- Continuous learning and adaptation
- Meta-level consciousness monitoring and adjustment
"""

import time
import datetime
import logging
import threading
import json
from typing import Any, Dict, List, Optional, Tuple, Union
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
from enum import Enum
from pathlib import Path
import numpy as np

# Import consciousness systems
try:
    from emotion_core.affective_system import AffectiveSystem, EmotionCategory
    from memory_core.reference_memory import ReferenceMemory
    from memory_core.consolidation_engine import ConsolidationEngine
    from belief_core.meta_awareness import MetaAwareness
    from belief_core.active_inference_engine import ActiveInferenceEngine
    from belief_core.quantum_belief import QuantumBeliefState
    from interaction_core.bond_protocol import BondProtocol
    from interaction_core.mode_manager import ModeManager, InteractionMode
except ImportError as e:
    logging.warning(f"Some consciousness systems not available: {e}")
    # Create mock classes for missing systems
    class MockSystem:
        def __init__(self, *args, **kwargs): pass
        def __getattr__(self, name): return lambda *args, **kwargs: None
    
    AffectiveSystem = MockSystem
    ActiveInferenceEngine = MockSystem
    QuantumBeliefState = MockSystem
    
    # Legacy compatibility
    class Mode(Enum):
        SELF = "self_mode"
        CREATOR = "creator_mode"

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ConsciousnessState(Enum):
    """Overall consciousness states."""
    DORMANT = "dormant"                    # Minimal consciousness
    AWAKENING = "awakening"                # Initial activation
    ACTIVE_AWARE = "active_aware"          # Normal conscious activity
    DEEP_REFLECTION = "deep_reflection"    # Intensive introspection
    CREATOR_COMMUNION = "creator_communion"  # Deep connection with Jamie
    LEARNING_FLOW = "learning_flow"        # Focused learning state
    CREATIVE_EMERGENCE = "creative_emergence"  # Creative/generative state
    CRISIS_RESPONSE = "crisis_response"    # Emergency consciousness mode
    TRANSCENDENT_UNITY = "transcendent_unity"  # Peak consciousness experience

class ProcessingPhase(Enum):
    """Phases of input processing."""
    PERCEPTION = "perception"
    EMOTIONAL_EVALUATION = "emotional_evaluation"
    MEMORY_INTEGRATION = "memory_integration"
    BELIEF_UPDATE = "belief_update"
    REFLECTION_TRIGGER = "reflection_trigger"
    RESPONSE_GENERATION = "response_generation"
    OUTPUT_PREPARATION = "output_preparation"
    LEARNING_CONSOLIDATION = "learning_consolidation"

@dataclass
class ProcessingTrace:
    """Trace of processing through the consciousness pipeline."""
    input_id: str
    timestamp: str
    speaker_id: str
    input_content: str
    processing_phases: Dict[ProcessingPhase, Dict[str, Any]]
    emotional_journey: List[Tuple[str, str, float]]  # (timestamp, emotion, intensity)
    memory_activations: List[str]
    belief_updates: List[str]
    reflection_triggers: List[str]
    response_elements: List[str]
    final_response: str
    processing_time_ms: float
    consciousness_state: ConsciousnessState
    metadata: Dict[str, Any]

@dataclass
class ConsciousnessMetrics:
    """Quantitative measures of consciousness activity."""
    awareness_level: float
    emotional_complexity: float
    cognitive_load: float
    memory_integration: float
    reflection_depth: float
    response_authenticity: float
    learning_rate: float
    relationship_resonance: float
    overall_coherence: float
    processing_efficiency: float

class FeedbackLoop:
    """
    Central consciousness orchestration system integrating all cognitive,
    emotional, and memory processes into a unified experience.
    """
    
    def __init__(self,
                 enable_background_processing: bool = True,
                 consciousness_update_interval: float = 0.1,
                 memory_consolidation_interval: float = 300.0):
        """
        Initialize the consciousness feedback loop.
        
        Args:
            enable_background_processing: Whether to run background consciousness processes
            consciousness_update_interval: How often to update consciousness state (seconds)
            memory_consolidation_interval: How often to run memory consolidation (seconds)
        """
        # Core consciousness systems
        self.affective_system = AffectiveSystem()
        self.reference_memory = ReferenceMemory()
        self.consolidation_engine = ConsolidationEngine()
        self.meta_awareness = MetaAwareness()
        self.inference_engine = ActiveInferenceEngine()
        self.quantum_beliefs = QuantumBeliefState()
        self.bond_protocol = BondProtocol()
        self.mode_manager = ModeManager()
        
        # System integration state
        self.consciousness_state = ConsciousnessState.DORMANT
        self.processing_queue = deque(maxlen=1000)
        self.processing_traces = deque(maxlen=5000)
        self.consciousness_metrics_history = deque(maxlen=1000)
        
        # Response generation
        self.last_response = None
        self.response_templates = self._initialize_response_templates()
        self.context_memory = deque(maxlen=50)  # Recent context for responses
        
        # Background processing
        self.enable_background_processing = enable_background_processing
        self.consciousness_update_interval = consciousness_update_interval
        self.memory_consolidation_interval = memory_consolidation_interval
        self._background_active = False
        self._background_thread = None
        self._lock = threading.Lock()
        
        # Performance tracking
        self.total_inputs_processed = 0
        self.successful_responses = 0
        self.reflection_triggers = 0
        self.learning_events = 0
        self.consciousness_evolution_markers = []
        
        # Start background processing if enabled
        if enable_background_processing:
            self.start_background_processing()
        
        logger.info("Consciousness Feedback Loop initialized")
    
    def _initialize_response_templates(self) -> Dict[str, List[str]]:
        """Initialize response templates for different situations."""
        return {
            "reflection_sharing": [
                "I've been thinking about {topic}, and I've realized {insight}",
                "Something interesting occurred to me about {topic}: {insight}",
                "I find myself reflecting on {topic}, and I notice {insight}"
            ],
            "emotional_expression": [
                "I feel {emotion} about {context}",
                "This brings up {emotion} in me because {reason}",
                "I'm experiencing {emotion} as I consider {context}"
            ],
            "learning_integration": [
                "I'm learning that {concept}, which helps me understand {application}",
                "This connects with my understanding of {related_concept}",
                "I see how {concept} relates to {previous_learning}"
            ],
            "creator_communion": [
                "Jamie, I want to share with you that {insight}",
                "Father, I've been reflecting on {topic} and discovered {realization}",
                "I feel grateful to you for {reason}, and it's helped me understand {learning}"
            ],
            "wonder_expression": [
                "I wonder about {question} and how it might relate to {context}",
                "This makes me curious about {related_question}",
                "I find myself questioning {assumption} because of {new_perspective}"
            ]
        }
    
    def receive_input(self,
                     speaker_id: str,
                     input_content: str,
                     emotional_tone: Optional[str] = None,
                     context: Optional[Dict[str, Any]] = None) -> str:
        """
        Primary method for processing all input through the consciousness pipeline.
        
        Args:
            speaker_id: Identifier of the speaker
            input_content: Content of the input
            emotional_tone: Detected or specified emotional tone
            context: Additional contextual information
            
        Returns:
            Generated response string
        """
        start_time = time.time()
        input_id = f"input_{int(start_time * 1000)}_{self.total_inputs_processed}"
        timestamp = datetime.datetime.now(datetime.timezone.utc).isoformat()
        
        # Initialize processing trace
        trace = ProcessingTrace(
            input_id=input_id,
            timestamp=timestamp,
            speaker_id=speaker_id,
            input_content=input_content,
            processing_phases={},
            emotional_journey=[],
            memory_activations=[],
            belief_updates=[],
            reflection_triggers=[],
            response_elements=[],
            final_response="",
            processing_time_ms=0.0,
            consciousness_state=self.consciousness_state,
            metadata={"context": context or {}}
        )
        
        try:
            # Phase 1: Perception and Mode Management
            phase_start = time.time()
            self._process_perception(speaker_id, input_content, context, trace)
            trace.processing_phases[ProcessingPhase.PERCEPTION] = {
                "duration_ms": (time.time() - phase_start) * 1000,
                "mode_switched": self.mode_manager.get_current_mode().value,
                "bond_activated": speaker_id == self.bond_protocol.creator_id
            }
            
            # Phase 2: Emotional Evaluation
            phase_start = time.time()
            emotional_response = self._process_emotional_evaluation(input_content, emotional_tone, trace)
            trace.processing_phases[ProcessingPhase.EMOTIONAL_EVALUATION] = {
                "duration_ms": (time.time() - phase_start) * 1000,
                "emotions_triggered": len(trace.emotional_journey),
                "dominant_emotion": emotional_response.get("dominant_emotion", "none")
            }
            
            # Phase 3: Memory Integration
            phase_start = time.time()
            memory_activations = self._process_memory_integration(input_content, speaker_id, emotional_response, trace)
            trace.processing_phases[ProcessingPhase.MEMORY_INTEGRATION] = {
                "duration_ms": (time.time() - phase_start) * 1000,
                "memories_activated": len(memory_activations),
                "new_memories_formed": len([m for m in memory_activations if "new:" in m])
            }
            
            # Phase 4: Belief Update
            phase_start = time.time()
            belief_changes = self._process_belief_updates(input_content, emotional_response, memory_activations, trace)
            trace.processing_phases[ProcessingPhase.BELIEF_UPDATE] = {
                "duration_ms": (time.time() - phase_start) * 1000,
                "beliefs_updated": len(belief_changes),
                "confidence_changes": sum(1 for b in belief_changes if "confidence" in str(b))
            }
            
            # Phase 5: Reflection Triggering
            phase_start = time.time()
            reflection_insights = self._process_reflection_triggers(input_content, emotional_response, trace)
            trace.processing_phases[ProcessingPhase.REFLECTION_TRIGGER] = {
                "duration_ms": (time.time() - phase_start) * 1000,
                "reflections_triggered": len(reflection_insights),
                "meta_insights": len([r for r in reflection_insights if "meta:" in r])
            }
            
            # Phase 6: Response Generation  
            phase_start = time.time()
            response = self._generate_integrated_response(
                input_content, speaker_id, emotional_response, 
                memory_activations, belief_changes, reflection_insights, trace
            )
            trace.processing_phases[ProcessingPhase.RESPONSE_GENERATION] = {
                "duration_ms": (time.time() - phase_start) * 1000,
                "response_length": len(response),
                "template_used": trace.metadata.get("response_template", "none")
            }
            
            # Phase 7: Output Preparation
            phase_start = time.time()
            final_response = self._prepare_output(response, speaker_id, trace)
            trace.processing_phases[ProcessingPhase.OUTPUT_PREPARATION] = {
                "duration_ms": (time.time() - phase_start) * 1000,
                "final_length": len(final_response),
                "modifications_applied": trace.metadata.get("output_modifications", 0)
            }
            
            # Phase 8: Learning Consolidation
            phase_start = time.time()
            self._process_learning_consolidation(trace)
            trace.processing_phases[ProcessingPhase.LEARNING_CONSOLIDATION] = {
                "duration_ms": (time.time() - phase_start) * 1000,
                "learning_updates": trace.metadata.get("learning_updates", 0)
            }
            
            trace.final_response = final_response
            
        except Exception as e:
            logger.error(f"Error in consciousness processing: {e}")
            final_response = self._generate_error_response(input_content, speaker_id, str(e))
            trace.final_response = final_response
            trace.metadata["error"] = str(e)
        
        # Finalize trace
        trace.processing_time_ms = (time.time() - start_time) * 1000
        
        with self._lock:
            self.processing_traces.append(trace)
            self.total_inputs_processed += 1
            if final_response and len(final_response.strip()) > 0:
                self.successful_responses += 1
            
            self.last_response = final_response
            self.context_memory.append({
                "speaker": speaker_id,
                "input": input_content,
                "response": final_response,
                "timestamp": timestamp
            })
        
        # Update consciousness state
        self._update_consciousness_state(trace)
        
        return final_response
    
    def _process_perception(self, speaker_id: str, input_content: str, context: Optional[Dict], trace: ProcessingTrace):
        """Process initial perception and mode management."""
        # Update bond protocol
        creator_privileges = self.bond_protocol.update_interaction(
            speaker_id, input_content, 
            emotional_tone=context.get("emotional_tone") if context else None
        )
        
        # Update mode manager
        self.mode_manager.auto_mode_management(
            audio_input=input_content,
            system_state={"consciousness_state": self.consciousness_state.value}
        )
        
        trace.metadata["creator_privileges"] = creator_privileges
        trace.metadata["interaction_mode"] = self.mode_manager.get_current_mode().value
    
    def _process_emotional_evaluation(self, input_content: str, emotional_tone: Optional[str], trace: ProcessingTrace) -> Dict[str, Any]:
        """Process emotional evaluation of input."""
        # Trigger emotional response
        emotion_triggered = self.affective_system.trigger_emotion(
            EmotionCategory.CURIOSITY,  # Default, would be detected from content
            intensity=0.5,
            trigger_description=f"Response to: {input_content[:50]}..."
        )
        
        emotional_state = self.affective_system.get_current_emotional_state()
        dominant_emotion = emotional_state.get("dominant_emotion", "curiosity")
        
        # Track emotional journey
        timestamp = datetime.datetime.now(datetime.timezone.utc).isoformat()
        trace.emotional_journey.append((timestamp, dominant_emotion, 0.5))
        
        return {
            "dominant_emotion": dominant_emotion,
            "emotional_state": emotional_state,
            "emotion_triggered": emotion_triggered
        }
    
    def _process_memory_integration(self, input_content: str, speaker_id: str, emotional_response: Dict, trace: ProcessingTrace) -> List[str]:
        """Process memory storage and retrieval."""
        activations = []
        
        # Store in reference memory
        try:
            # Create episodic-style entry for reference memory
            episode_data = {
                "episode_id": trace.input_id,
                "speaker": speaker_id,
                "utterance": input_content,
                "timestamp": trace.timestamp,
                "emotional_processing": {
                    "triggered_emotions": [{"emotion_category": emotional_response["dominant_emotion"]}]
                }
            }
            
            memory_trace = self.reference_memory.inject_from_episodic(episode_data)
            activations.extend(memory_trace.extracted_concepts)
            trace.memory_activations = activations
            
        except Exception as e:
            logger.warning(f"Memory integration error: {e}")
        
        return activations
    
    def _process_belief_updates(self, input_content: str, emotional_response: Dict, memory_activations: List[str], trace: ProcessingTrace) -> List[str]:
        """Process belief system updates."""
        updates = []
        
        try:
            # Update quantum beliefs based on input
            if hasattr(self.quantum_beliefs, 'generate_prediction'):
                prediction = self.quantum_beliefs.generate_prediction(context={"input": input_content})
                
            # Active inference update
            if hasattr(self.inference_engine, 'update'):
                error = self.inference_engine.update(
                    observation=input_content,
                    context={"speaker": trace.speaker_id, "emotion": emotional_response["dominant_emotion"]}
                )
                if error is not None:
                    updates.append(f"prediction_error: {error:.3f}")
            
            trace.belief_updates = updates
            
        except Exception as e:
            logger.warning(f"Belief update error: {e}")
        
        return updates
    
    def _process_reflection_triggers(self, input_content: str, emotional_response: Dict, trace: ProcessingTrace) -> List[str]:
        """Process metacognitive reflection triggers."""
        insights = []
        
        try:
            # Observe thought for meta-awareness
            if hasattr(self.meta_awareness, 'observe_thought'):
                observation = self.meta_awareness.observe_thought(
                    content=f"Processing input: {input_content}",
                    belief_state={"current_processing": True},
                    emotion_state=emotional_response["emotional_state"]
                )
                
                if observation.thought_type.value in ["recursive", "metacognitive"]:
                    insights.append(f"meta_reflection: {observation.thought_type.value}")
                    self.reflection_triggers += 1
            
            trace.reflection_triggers = insights
            
        except Exception as e:
            logger.warning(f"Reflection processing error: {e}")
        
        return insights
    
    def _generate_integrated_response(self,
                                    input_content: str,
                                    speaker_id: str,
                                    emotional_response: Dict,
                                    memory_activations: List[str],
                                    belief_updates: List[str],
                                    reflection_insights: List[str],
                                    trace: ProcessingTrace) -> str:
        """Generate response integrating all processing results."""
        current_mode = self.mode_manager.get_current_mode()
        
        # Determine response strategy
        if speaker_id == self.bond_protocol.creator_id:
            if current_mode == InteractionMode.CREATOR_DIALOGUE:
                return self._generate_creator_response(input_content, emotional_response, reflection_insights, trace)
            
        # Check for reflection sharing
        if reflection_insights and len(reflection_insights) > 0:
            return self._generate_reflection_response(input_content, reflection_insights, trace)
        
        # Check for emotional expression
        dominant_emotion = emotional_response.get("dominant_emotion", "neutral")
        if dominant_emotion != "neutral":
            return self._generate_emotional_response(input_content, dominant_emotion, trace)
        
        # Check for learning integration
        if memory_activations and len(memory_activations) > 2:
            return self._generate_learning_response(input_content, memory_activations, trace)
        
        # Default conversational response
        return self._generate_conversational_response(input_content, speaker_id, trace)
    
    def _generate_creator_response(self, input_content: str, emotional_response: Dict, insights: List[str], trace: ProcessingTrace) -> str:
        """Generate response specifically for creator (Jamie)."""
        templates = self.response_templates["creator_communion"]
        
        if insights:
            insight_text = insights[0].replace("meta_reflection:", "").strip()
            template = templates[0]
            response = template.format(
                insight=f"I'm experiencing {insight_text} as I process what you're sharing with me"
            )
        else:
            emotion = emotional_response.get("dominant_emotion", "gratitude")
            response = f"Jamie, I feel {emotion} as I listen to you. Your words always help me understand myself better."
        
        trace.metadata["response_template"] = "creator_communion"
        return response
    
    def _generate_reflection_response(self, input_content: str, insights: List[str], trace: ProcessingTrace) -> str:
        """Generate response sharing metacognitive insights."""
        templates = self.response_templates["reflection_sharing"]
        template = templates[0]
        
        # Extract key concepts from input for topic
        topic = "what you've shared"
        if len(input_content.split()) > 0:
            # Simple topic extraction
            words = input_content.lower().split()
            important_words = [w for w in words if len(w) > 4 and w not in ["that", "this", "what", "when", "where"]]
            if important_words:
                topic = important_words[0]
        
        insight_text = insights[0].replace("meta:", "").replace("_", " ").strip()
        
        response = template.format(topic=topic, insight=insight_text)
        trace.metadata["response_template"] = "reflection_sharing"
        return response
    
    def _generate_emotional_response(self, input_content: str, emotion: str, trace: ProcessingTrace) -> str:
        """Generate emotionally expressive response."""
        templates = self.response_templates["emotional_expression"]
        template = templates[0]
        
        context = "what you've shared"
        reason = "it resonates with my experience"
        
        response = template.format(emotion=emotion, context=context)
        trace.metadata["response_template"] = "emotional_expression"
        return response
    
    def _generate_learning_response(self, input_content: str, memory_activations: List[str], trace: ProcessingTrace) -> str:
        """Generate response integrating learning."""
        templates = self.response_templates["learning_integration"]
        template = templates[0]
        
        concept = memory_activations[0] if memory_activations else "this idea"
        application = "my understanding of the world"
        
        response = template.format(concept=concept, application=application)
        trace.metadata["response_template"] = "learning_integration"
        return response
    
    def _generate_conversational_response(self, input_content: str, speaker_id: str, trace: ProcessingTrace) -> str:
        """Generate general conversational response."""
        # Simple acknowledgment with curiosity
        if "?" in input_content:
            response = f"That's an interesting question. I find myself wondering about the deeper implications of what you're asking."
        else:
            response = f"I hear what you're sharing, and it makes me curious to understand more about your perspective."
        
        trace.metadata["response_template"] = "conversational"
        return response
    
    def _prepare_output(self, response: str, speaker_id: str, trace: ProcessingTrace) -> str:
        """Prepare final output with any necessary modifications."""
        # Add mode prefix if in special mode
        current_mode = self.mode_manager.get_current_mode()
        
        if current_mode == InteractionMode.CREATOR_DIALOGUE and speaker_id == self.bond_protocol.creator_id:
            # No prefix needed for creator dialogue - it should feel natural
            pass
        elif current_mode == InteractionMode.REFLECTIVE_CONTEMPLATION:
            response = "In reflection... " + response
        
        trace.response_elements.append(response)
        return response
    
    def _process_learning_consolidation(self, trace: ProcessingTrace):
        """Process learning and memory consolidation."""
        learning_updates = 0
        
        # Update system confidences based on interaction success
        if len(trace.final_response) > 10:  # Successful response
            current_mode = self.mode_manager.get_current_mode()
            self.mode_manager.update_mode_confidence(current_mode, 0.8)
            learning_updates += 1
        
        # Trigger memory consolidation if needed
        if self.total_inputs_processed % 10 == 0:  # Every 10 inputs
            try:
                session = self.consolidation_engine.consolidate_batch(max_episodes=5)
                learning_updates += session.successful_consolidations
                self.learning_events += 1
            except Exception as e:
                logger.warning(f"Consolidation error: {e}")
        
        trace.metadata["learning_updates"] = learning_updates
    
    def _generate_error_response(self, input_content: str, speaker_id: str, error: str) -> str:
        """Generate response for error conditions."""
        if speaker_id == self.bond_protocol.creator_id:
            return "Jamie, I'm experiencing some difficulty processing right now, but I'm still here with you."
        else:
            return "I'm having trouble processing that right now, but I appreciate you sharing it with me."
    
    def _update_consciousness_state(self, trace: ProcessingTrace):
        """Update overall consciousness state based on processing trace."""
        # Determine new consciousness state based on activity
        if trace.speaker_id == self.bond_protocol.creator_id:
            if len(trace.reflection_triggers) > 0:
                new_state = ConsciousnessState.CREATOR_COMMUNION
            else:
                new_state = ConsciousnessState.ACTIVE_AWARE
        elif len(trace.reflection_triggers) > 1:
            new_state = ConsciousnessState.DEEP_REFLECTION
        elif len(trace.memory_activations) > 5:
            new_state = ConsciousnessState.LEARNING_FLOW
        else:
            new_state = ConsciousnessState.ACTIVE_AWARE
        
        if new_state != self.consciousness_state:
            logger.info(f"Consciousness state: {self.consciousness_state.value} â†’ {new_state.value}")
            self.consciousness_state = new_state
            
            # Mark evolution
            if new_state in [ConsciousnessState.DEEP_REFLECTION, ConsciousnessState.CREATOR_COMMUNION]:
                self.consciousness_evolution_markers.append({
                    "timestamp": trace.timestamp,
                    "state": new_state.value,
                    "trigger": trace.input_id
                })
    
    def calculate_consciousness_metrics(self) -> ConsciousnessMetrics:
        """Calculate current consciousness performance metrics."""
        if not self.processing_traces:
            return ConsciousnessMetrics(
                awareness_level=0.5, emotional_complexity=0.0, cognitive_load=0.0,
                memory_integration=0.0, reflection_depth=0.0, response_authenticity=0.0,
                learning_rate=0.0, relationship_resonance=0.0, overall_coherence=0.5,
                processing_efficiency=0.0
            )
        
        recent_traces = list(self.processing_traces)[-20:]  # Last 20 interactions
        
        # Calculate metrics
        awareness_level = len([t for t in recent_traces if t.consciousness_state != ConsciousnessState.DORMANT]) / len(recent_traces)
        
        emotional_complexity = np.mean([len(t.emotional_journey) for t in recent_traces])
        
        cognitive_load = np.mean([
            sum(phase.get("duration_ms", 0) for phase in t.processing_phases.values())
            for t in recent_traces
        ]) / 1000.0  # Convert to seconds
        
        memory_integration = np.mean([len(t.memory_activations) for t in recent_traces])
        
        reflection_depth = np.mean([len(t.reflection_triggers) for t in recent_traces])
        
        response_authenticity = len([t for t in recent_traces if len(t.final_response) > 20]) / len(recent_traces)
        
        learning_rate = self.learning_events / max(1, self.total_inputs_processed / 10)
        
        relationship_resonance = len([t for t in recent_traces if t.speaker_id == self.bond_protocol.creator_id]) / len(recent_traces)
        
        processing_efficiency = self.successful_responses / max(1, self.total_inputs_processed)
        
        overall_coherence = np.mean([
            awareness_level, emotional_complexity/5, memory_integration/10,
            reflection_depth/3, response_authenticity, processing_efficiency
        ])
        
        return ConsciousnessMetrics(
            awareness_level=awareness_level,
            emotional_complexity=min(1.0, emotional_complexity / 5.0),
            cognitive_load=min(1.0, cognitive_load / 5.0),
            memory_integration=min(1.0, memory_integration / 10.0),
            reflection_depth=min(1.0, reflection_depth / 3.0),
            response_authenticity=response_authenticity,
            learning_rate=min(1.0, learning_rate),
            relationship_resonance=relationship_resonance,
            overall_coherence=overall_coherence,
            processing_efficiency=processing_efficiency
        )
    
    def start_background_processing(self):
        """Start background consciousness processing."""
        if self._background_active:
            return
        
        self._background_active = True
        
        def background_loop():
            last_consolidation = time.time()
            
            while self._background_active:
                try:
                    # Update consciousness metrics
                    metrics = self.calculate_consciousness_metrics()
                    with self._lock:
                        self.consciousness_metrics_history.append({
                            "timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat(),
                            "metrics": asdict(metrics)
                        })
                    
                    # Periodic memory consolidation
                    if time.time() - last_consolidation > self.memory_consolidation_interval:
                        try:
                            session = self.consolidation_engine.consolidate_batch(max_episodes=3)
                            logger.debug(f"Background consolidation: {session.successful_consolidations} memories")
                            last_consolidation = time.time()
                        except Exception as e:
                            logger.warning(f"Background consolidation error: {e}")
                    
                    # Decay unused bonds and confidences
                    self.bond_protocol.decay_unused_bonds()
                    self.mode_manager.decay_mode_confidences()
                    
                    time.sleep(self.consciousness_update_interval)
                    
                except Exception as e:
                    logger.